{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6599a5b6-7728-4b7c-b26e-dcdc04f3d572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|            features|\n",
      "+---+--------------------+\n",
      "|  0|(20,[0,6,15,16],[...|\n",
      "|  1|(20,[4,6,8,9,10,1...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature.{HashingTF, IDF, Tokenizer}\r\n",
       "import org.apache.spark.ml.linalg.Vector\r\n",
       "import org.apache.spark.sql.functions._\r\n",
       "df: org.apache.spark.sql.DataFrame = [id: int, text: string]\r\n",
       "tokenizer: org.apache.spark.ml.feature.Tokenizer = tok_0c64dd8cab14\r\n",
       "wordsData: org.apache.spark.sql.DataFrame = [id: int, text: string ... 1 more field]\r\n",
       "hashingTF: org.apache.spark.ml.feature.HashingTF = HashingTF: uid=hashingTF_fc2a910171e8, binary=false, numFeatures=20\r\n",
       "featurizedData: org.apache.spark.sql.DataFrame = [id: int, text: string ... 2 more fields]\r\n",
       "idf: org.apache.spark.ml.feature.IDF = idf_a0328663a564\r\n",
       "idfModel: org.apache.spark.ml.feature.IDFModel = IDFModel: uid=idf_a0328663a564, numDocs=2, numFeatures=20\r\n",
       "rescaledData: org.apache.spark.sql.DataFrame = [id: int,...\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.{HashingTF, IDF, Tokenizer}\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "// Sample DataFrame with cleaned and tokenized text\n",
    "val df = Seq(\n",
    "  (0, \"I love Spark MLlib\"),\n",
    "  (1, \"MLlib is great for processing big data\")\n",
    ").toDF(\"id\", \"text\")\n",
    "\n",
    "// Tokenize text\n",
    "val tokenizer = new Tokenizer().setInputCol(\"text\").setOutputCol(\"words\")\n",
    "val wordsData = tokenizer.transform(df)\n",
    "\n",
    "// HashingTF\n",
    "val hashingTF = new HashingTF()\n",
    "  .setInputCol(\"words\").setOutputCol(\"rawFeatures\").setNumFeatures(20)\n",
    "val featurizedData = hashingTF.transform(wordsData)\n",
    "\n",
    "// IDF\n",
    "val idf = new IDF().setInputCol(\"rawFeatures\").setOutputCol(\"features\")\n",
    "val idfModel = idf.fit(featurizedData)\n",
    "val rescaledData = idfModel.transform(featurizedData)\n",
    "\n",
    "rescaledData.select(\"id\", \"features\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f87e022d-3646-4a31-ba63-883995d00a6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "java.lang.IllegalArgumentException",
     "evalue": " label does not exist. Available: id, text, words, rawFeatures, features\r",
     "output_type": "error",
     "traceback": [
      "java.lang.IllegalArgumentException: label does not exist. Available: id, text, words, rawFeatures, features\r",
      "  at org.apache.spark.sql.types.StructType.$anonfun$apply$1(StructType.scala:280)\r",
      "  at scala.collection.immutable.HashMap$HashTrieMap.getOrElse0(HashMap.scala:596)\r",
      "  at scala.collection.immutable.HashMap.getOrElse(HashMap.scala:73)\r",
      "  at org.apache.spark.sql.types.StructType.apply(StructType.scala:279)\r",
      "  at org.apache.spark.ml.util.SchemaUtils$.checkNumericType(SchemaUtils.scala:75)\r",
      "  at org.apache.spark.ml.PredictorParams.validateAndTransformSchema(Predictor.scala:51)\r",
      "  at org.apache.spark.ml.PredictorParams.validateAndTransformSchema$(Predictor.scala:44)\r",
      "  at org.apache.spark.ml.classification.Classifier.org$apache$spark$ml$classification$ClassifierParams$$super$validateAndTransformSchema(Classifier.scala:53)\r",
      "  at org.apache.spark.ml.classification.ClassifierParams.validateAndTransformSchema(Classifier.scala:40)\r",
      "  at org.apache.spark.ml.classification.ClassifierParams.validateAndTransformSchema$(Classifier.scala:36)\r",
      "  at org.apache.spark.ml.classification.ProbabilisticClassifier.org$apache$spark$ml$classification$ProbabilisticClassifierParams$$super$validateAndTransformSchema(ProbabilisticClassifier.scala:51)\r",
      "  at org.apache.spark.ml.classification.ProbabilisticClassifierParams.validateAndTransformSchema(ProbabilisticClassifier.scala:38)\r",
      "  at org.apache.spark.ml.classification.ProbabilisticClassifierParams.validateAndTransformSchema$(ProbabilisticClassifier.scala:34)\r",
      "  at org.apache.spark.ml.classification.LogisticRegression.org$apache$spark$ml$classification$LogisticRegressionParams$$super$validateAndTransformSchema(LogisticRegression.scala:287)\r",
      "  at org.apache.spark.ml.classification.LogisticRegressionParams.validateAndTransformSchema(LogisticRegression.scala:270)\r",
      "  at org.apache.spark.ml.classification.LogisticRegressionParams.validateAndTransformSchema$(LogisticRegression.scala:257)\r",
      "  at org.apache.spark.ml.classification.LogisticRegression.validateAndTransformSchema(LogisticRegression.scala:287)\r",
      "  at org.apache.spark.ml.Predictor.transformSchema(Predictor.scala:140)\r",
      "  at org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:71)\r",
      "  at org.apache.spark.ml.Predictor.fit(Predictor.scala:96)\r",
      "  ... 44 elided\r",
      ""
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
