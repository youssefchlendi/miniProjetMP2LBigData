{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10dbf47f-4d94-4f9e-becc-b7435ced1a5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "2: error: ';' expected but '.' found.\r",
     "output_type": "error",
     "traceback": [
      "<console>:2: error: ';' expected but '.' found.\r",
      "       from IPython.display import clear_output\r",
      "                   ^\r",
      ""
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "!pip install nltk\n",
    "!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b67d9861-cf1f-4743-a66c-ac33f57a0713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@7080c32b\r\n",
       "import spark.implicits._\r\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Setting up spark session\n",
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession\n",
    "  .builder()\n",
    "  .appName(\"Twitter Sentiment Analysis\")\n",
    "  .getOrCreate()\n",
    "\n",
    "import spark.implicits._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c4261c5-c702-4056-a8c0-2c9cc930d8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "|target|       ids|                date|    flag|           user|                text|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "|     0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|     0|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|     0|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|     0|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|     0|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|     0|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|     0|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |\n",
      "|     0|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|     0|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|     0|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "|     0|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "|     0|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "|     0|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "|     0|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "|     0|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "|     0|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "|     0|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "|     0|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes |\n",
      "|     0|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "|     0|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datasetPath: String = ./temp/twitter/data.csv\r\n",
       "df: org.apache.spark.sql.DataFrame = [target: string, ids: string ... 4 more fields]\r\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Loading the dataset\n",
    "val datasetPath = \"./temp/twitter/data.csv\" \n",
    "val df = spark.read\n",
    "  .csv(datasetPath)\n",
    "  .toDF(\"target\",\"ids\",\"date\",\"flag\",\"user\",\"text\")\n",
    " \n",
    "\n",
    "df.show() // Show the first few rows of the DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "748332af-981a-4a0d-b25a-d0638fd10b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|target|                text|         cleanedText|\n",
      "+------+--------------------+--------------------+\n",
      "|     0|@switchfoot http:...|  - A that's a bu...|\n",
      "|     0|is upset that he ...|is upset that he ...|\n",
      "|     0|@Kenichan I dived...| I dived many tim...|\n",
      "|     0|my whole body fee...|my whole body fee...|\n",
      "|     0|@nationwideclass ...| no, it's not beh...|\n",
      "|     0|@Kwesidei not the...| not the whole crew |\n",
      "|     0|         Need a hug |         Need a hug |\n",
      "|     0|@LOLTrish hey  lo...| hey  long time n...|\n",
      "|     0|@Tatiana_K nope t...| nope they didn't...|\n",
      "|     0|@twittera que me ...|     que me muera ? |\n",
      "|     0|spring break in p...|spring break in p...|\n",
      "|     0|I just re-pierced...|I just re-pierced...|\n",
      "|     0|@caregiving I cou...| I couldn't bear ...|\n",
      "|     0|@octolinz16 It it...| It it counts, id...|\n",
      "|     0|@smarrison i woul...| i would've been ...|\n",
      "|     0|@iamjazzyfizzle I...| I wish I got to ...|\n",
      "|     0|Hollis' death sce...|Hollis' death sce...|\n",
      "|     0|about to file taxes |about to file taxes |\n",
      "|     0|@LettyA ahh ive a...| ahh ive always w...|\n",
      "|     0|@FakerPattyPattz ...| Oh dear. Were yo...|\n",
      "+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.udf\r\n",
       "import scala.util.matching.Regex\r\n",
       "cleanText: String => String\r\n",
       "cleanTextUDF: org.apache.spark.sql.expressions.UserDefinedFunction = SparkUserDefinedFunction($Lambda/0x000001c7842d0218@34dd8cd5,StringType,List(Some(class[value[0]: string])),Some(class[value[0]: string]),None,true,true)\r\n",
       "cleanedDf: org.apache.spark.sql.DataFrame = [target: string, text: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Cleaning the data\n",
    "import org.apache.spark.sql.functions.udf\n",
    "import scala.util.matching.Regex\n",
    "\n",
    "// Define a function to remove URLs, Twitter handles, and hashtags\n",
    "def cleanText: (String => String) = { text =>\n",
    "    // define a pattern to remove the urls\n",
    "    val urlPattern: Regex = new Regex(\"http\\\\S+|www\\\\S+|https\\\\S+\")\n",
    "    // define a pattern to remove the user names ( tags )\n",
    "    val userPattern: Regex = new Regex(\"@\\\\w+\")\n",
    "    // define a pattern to remove the hashtags\n",
    "    val hashtagPattern: Regex = new Regex(\"#\\\\w+\")\n",
    "    // clear urls\n",
    "    val result = urlPattern.replaceAllIn(text, \"\")\n",
    "    // clear tags\n",
    "    val result2 = userPattern.replaceAllIn(result, \"\")\n",
    "    // hashtags\n",
    "    hashtagPattern.replaceAllIn(result2, \"\")\n",
    "}\n",
    "\n",
    "// Register the UserDefinedFunction\n",
    "val cleanTextUDF = udf(cleanText)\n",
    "\n",
    "// drop the flag column \n",
    "\n",
    "// Apply the UDF to clean the text column \n",
    "// and removing the flag,date,user columns and ids because we'll not use them\n",
    "val cleanedDf = df.withColumn(\"cleanedText\", cleanTextUDF($\"text\")).drop(\"flag\",\"date\",\"user\",\"ids\")\n",
    "\n",
    "\n",
    "cleanedDf.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7cd22d56-1042-4b89-afc8-b94e8e41328c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+\n",
      "|target|                text|         cleanedText|               words|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "|     0|@switchfoot http:...|  - A that's a bu...|[, , -, a, that's...|\n",
      "|     0|is upset that he ...|is upset that he ...|[is, upset, that,...|\n",
      "|     0|@Kenichan I dived...| I dived many tim...|[, i, dived, many...|\n",
      "|     0|my whole body fee...|my whole body fee...|[my, whole, body,...|\n",
      "|     0|@nationwideclass ...| no, it's not beh...|[, no,, it's, not...|\n",
      "|     0|@Kwesidei not the...| not the whole crew |[, not, the, whol...|\n",
      "|     0|         Need a hug |         Need a hug |      [need, a, hug]|\n",
      "|     0|@LOLTrish hey  lo...| hey  long time n...|[, hey, , long, t...|\n",
      "|     0|@Tatiana_K nope t...| nope they didn't...|[, nope, they, di...|\n",
      "|     0|@twittera que me ...|     que me muera ? |[, que, me, muera...|\n",
      "|     0|spring break in p...|spring break in p...|[spring, break, i...|\n",
      "|     0|I just re-pierced...|I just re-pierced...|[i, just, re-pier...|\n",
      "|     0|@caregiving I cou...| I couldn't bear ...|[, i, couldn't, b...|\n",
      "|     0|@octolinz16 It it...| It it counts, id...|[, it, it, counts...|\n",
      "|     0|@smarrison i woul...| i would've been ...|[, i, would've, b...|\n",
      "|     0|@iamjazzyfizzle I...| I wish I got to ...|[, i, wish, i, go...|\n",
      "|     0|Hollis' death sce...|Hollis' death sce...|[hollis', death, ...|\n",
      "|     0|about to file taxes |about to file taxes |[about, to, file,...|\n",
      "|     0|@LettyA ahh ive a...| ahh ive always w...|[, ahh, ive, alwa...|\n",
      "|     0|@FakerPattyPattz ...| Oh dear. Were yo...|[, oh, dear., wer...|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature.Tokenizer\r\n",
       "tokenizer: org.apache.spark.ml.feature.Tokenizer = tok_914285766876\r\n",
       "tokenizedDf: org.apache.spark.sql.DataFrame = [target: string, text: string ... 2 more fields]\r\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Tokenization\n",
    "\n",
    "import org.apache.spark.ml.feature.Tokenizer\n",
    "\n",
    "// Instantiate the tokenizer\n",
    "val tokenizer = new Tokenizer().setInputCol(\"cleanedText\").setOutputCol(\"words\")\n",
    "\n",
    "// Transform the dataset\n",
    "val tokenizedDf = tokenizer.transform(cleanedDf)\n",
    "\n",
    "tokenizedDf.show(true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "079df206-ec95-4b05-bab2-30c4abedb3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+--------------------+\n",
      "|target|                text|         cleanedText|               words|       filteredWords|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+\n",
      "|     0|@switchfoot http:...|  - A that's a bu...|[, , -, a, that's...|[, , -, bummer., ...|\n",
      "|     0|is upset that he ...|is upset that he ...|[is, upset, that,...|[upset, update, f...|\n",
      "|     0|@Kenichan I dived...| I dived many tim...|[, i, dived, many...|[, dived, many, t...|\n",
      "|     0|my whole body fee...|my whole body fee...|[my, whole, body,...|[whole, body, fee...|\n",
      "|     0|@nationwideclass ...| no, it's not beh...|[, no,, it's, not...|[, no,, behaving,...|\n",
      "|     0|@Kwesidei not the...| not the whole crew |[, not, the, whol...|     [, whole, crew]|\n",
      "|     0|         Need a hug |         Need a hug |      [need, a, hug]|         [need, hug]|\n",
      "|     0|@LOLTrish hey  lo...| hey  long time n...|[, hey, , long, t...|[, hey, , long, t...|\n",
      "|     0|@Tatiana_K nope t...| nope they didn't...|[, nope, they, di...|            [, nope]|\n",
      "|     0|@twittera que me ...|     que me muera ? |[, que, me, muera...|   [, que, muera, ?]|\n",
      "|     0|spring break in p...|spring break in p...|[spring, break, i...|[spring, break, p...|\n",
      "|     0|I just re-pierced...|I just re-pierced...|[i, just, re-pier...|  [re-pierced, ears]|\n",
      "|     0|@caregiving I cou...| I couldn't bear ...|[, i, couldn't, b...|[, bear, watch, i...|\n",
      "|     0|@octolinz16 It it...| It it counts, id...|[, it, it, counts...|[, counts,, idk, ...|\n",
      "|     0|@smarrison i woul...| i would've been ...|[, i, would've, b...|[, would've, firs...|\n",
      "|     0|@iamjazzyfizzle I...| I wish I got to ...|[, i, wish, i, go...|[, wish, got, wat...|\n",
      "|     0|Hollis' death sce...|Hollis' death sce...|[hollis', death, ...|[hollis', death, ...|\n",
      "|     0|about to file taxes |about to file taxes |[about, to, file,...|       [file, taxes]|\n",
      "|     0|@LettyA ahh ive a...| ahh ive always w...|[, ahh, ive, alwa...|[, ahh, ive, alwa...|\n",
      "|     0|@FakerPattyPattz ...| Oh dear. Were yo...|[, oh, dear., wer...|[, oh, dear., dri...|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature.StopWordsRemover\r\n",
       "remover: org.apache.spark.ml.feature.StopWordsRemover = StopWordsRemover: uid=stopWords_57fcf0d1a32a, numStopWords=181, locale=fr_FR, caseSensitive=false\r\n",
       "filteredDf: org.apache.spark.sql.DataFrame = [target: string, text: string ... 3 more fields]\r\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Removing Stop Words\n",
    "import org.apache.spark.ml.feature.StopWordsRemover\n",
    "\n",
    "// Instantiate the StopWordsRemover\n",
    "val remover = new StopWordsRemover()\n",
    "  .setInputCol(\"words\")\n",
    "  .setOutputCol(\"filteredWords\")\n",
    "\n",
    "// Transform the dataset\n",
    "val filteredDf = remover.transform(tokenizedDf)\n",
    "\n",
    "filteredDf.show(true)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
